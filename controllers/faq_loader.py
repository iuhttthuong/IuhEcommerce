import os, re, json5
from fastapi import APIRouter
from sqlalchemy.orm import Session
from db import Session as db_session
from models.fqas import FQA
from typing import List
from datetime import datetime
from env import env
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from autogen import AssistantAgent
import json

router = APIRouter(prefix="/load-faq", tags=["Load PDF folder for FAQ"])

PDF_FOLDER = "tiki_policies"  # ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a file PDF

# 1. Tr√≠ch xu·∫•t n·ªôi dung t·ª´ 1 file PDF
def extract_text_from_pdf_path(file_path: str) -> str:
    with open(file_path, "rb") as f:
        reader = PdfReader(f)
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
    return text.strip()

# 2. Chunk vƒÉn b·∫£n
def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 100) -> List[str]:
    splitter = CharacterTextSplitter(separator="\n", chunk_size=chunk_size, chunk_overlap=overlap)
    return splitter.split_text(text)

# 3. G·ªçi LLM ƒë·ªÉ sinh c√¢u h·ªèi - c√¢u tr·∫£ l·ªùi t·ª´ 1 chunk
def generate_faq_from_chunk(chunk: str) -> List[dict]:


    system_message = f"""T·∫°o c√°c c·∫∑p c√¢u h·ªèi - c√¢u tr·∫£ l·ªùi t·ª´ ƒëo·∫°n vƒÉn m√† ng∆∞·ªùi d√πng cung c·∫•p b·∫±ng ti·∫øng Vi·ªát:
    H√£y ph√¢n t√≠ch c·∫©n th·∫≠n v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON, tuy·ªát ƒë·ªëi kh√¥ng c√≥ g√¨ kh√°c, ƒë·∫∑c bi·ªát l√† kh√¥ng c√≥ d·∫•u ngo·∫∑c k√©p ·ªü ƒë·∫ßu v√† cu·ªëi.:
    [{{"question": "...", "answer": "..."}}]

    """
    agent = AssistantAgent(
        name="controller",
        system_message=system_message,
        llm_config={
                "model": "llama3-70b-8192",
                "api_key": env.GROQ_API_KEY,
                "api_type": "groq",
            }
    )
    user_message = {"role": "user", "content": chunk}
    response = agent.generate_reply(
        messages=[user_message],
        function_call={"name": "extract_product"}
    )

    data = re.sub("Tiki", "IUH-Ecommerce", response["content"], flags=re.IGNORECASE)



    
    match = re.search(r'\[.*\]', data, re.DOTALL)

    
    if match:
        try:
            json_str = match.group(0)
            data = json.loads(json_str)
            print("‚ùé‚úÖü§£üíïüòòüòäüòç")
            print(data)
        except json.JSONDecodeError as e:
            print(f"L·ªói khi gi·∫£i m√£ JSON: {e}")
            print(match.group(0))
    else:
        print("Kh√¥ng t√¨m th·∫•y JSON.")
    
    if isinstance(data, list):
        return data
    else:
        print("D·ªØ li·ªáu kh√¥ng ph·∫£i l√† danh s√°ch.")
        print(data)
        return []


# 4. L∆∞u k·∫øt qu·∫£ v√†o DB
def save_faqs_to_db(faqs: List[dict]):
    with db_session() as session:
        for faq in faqs:
            record = FQA(
                question=faq["question"],
                answer=faq["answer"],
                created_at=datetime.utcnow()
            )
            session.add(record)
        session.commit()

# 5. API ƒë·ªÉ load to√†n b·ªô file PDF trong th∆∞ m·ª•c
@router.post("/")
def process_pdf_folder():
    if not os.path.exists(PDF_FOLDER):
        return {"message": f"Th∆∞ m·ª•c '{PDF_FOLDER}' kh√¥ng t·ªìn t·∫°i."}

    total_faqs = 0
    for filename in os.listdir(PDF_FOLDER):
        if filename.lower().endswith(".pdf"):
            print(f"ƒêang x·ª≠ l√Ω file: {filename}")
            path = os.path.join(PDF_FOLDER, filename)
            text = extract_text_from_pdf_path(path)
            chunks = chunk_text(text)
            for chunk in chunks:
                faqs = generate_faq_from_chunk(chunk)
                
                if faqs:
                    save_faqs_to_db(faqs)
                    total_faqs += len(faqs)
            os.remove(path)



    return {"message": f"ƒê√£ x·ª≠ l√Ω th∆∞ m·ª•c PDF. T·ªïng s·ªë Q&A ƒë∆∞·ª£c l∆∞u: {total_faqs}"}




