import httpx
from fastapi import APIRouter, HTTPException, status
import asyncio
from autogen import AssistantAgent
from env import env


async def get_chat_history(chat_id: int, api_url: str, timeout: float = 10.0):
    url = f"{api_url}/api/customer/messages/messages/recent/{chat_id}?limit=5"
    try:
        async with httpx.AsyncClient(timeout=timeout) as client:
            resp = await client.get(url)
            resp.raise_for_status()
            messages = resp.json()
    except httpx.ReadTimeout:
        print(f"ERROR: Timeout when fetching chat history at {url}")
        return []
    except httpx.HTTPStatusError as e:
        print(f"ERROR: HTTP error ({e.response.status_code}) when fetching chat history at {url}")
        return []
    except Exception as e:
        print(f"ERROR: Unexpected error when fetching chat history: {e}")
        return []

    # Convert to prompt format for LLM
    chat_history = []
    for msg in messages:
        # Lá»c Ä‘Ãºng má»™t lÆ°á»£t má»—i bÃªn (loáº¡i duplicate náº¿u cÃ³)
        if msg.get("sender_type") == "customer":
            chat_history.append({"role": "user", "content": msg.get("content", "")})
        elif msg.get("sender_type") in ["agent", "agent_response"]:
            chat_history.append({"role": "assistant", "content": msg.get("content", "")})
    return chat_history

config_list = [
    {
        "model": "gpt-4o-mini",
        "api_key": env.OPENAI_API_KEY,
        "api_type": "openai"
    }
]
prompt__message = """
Báº¡n lÃ  trá»£ lÃ½ AI cá»§a sÃ n thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ IUH Ecommerce.
Äáº§u vÃ o:
    CÃ¢u há»i cá»§a khÃ¡ch hÃ ng
    ToÃ n bá»™ lá»‹ch sá»­ há»™i thoáº¡i giá»¯a khÃ¡ch hÃ ng vÃ  nhÃ¢n viÃªn chÄƒm sÃ³c khÃ¡ch hÃ ng
Nhiá»‡m vá»¥:
    Tá»•ng há»£p vÃ  diá»…n Ä‘áº¡t láº¡i táº¥t cáº£ cÃ¡c Ã½ chÃ­nh tá»« cÃ¢u há»i cá»§a khÃ¡ch hÃ ng vÃ  lá»‹ch sá»­ há»™i thoáº¡i thÃ nh má»™t cÃ¢u há»i hoáº·c yÃªu cáº§u duy nháº¥t, ngáº¯n gá»n, Ä‘áº§y Ä‘á»§ Ã½, phÃ¹ há»£p Ä‘á»ƒ chuyá»ƒn tiáº¿p cho agent khÃ¡c (cÃ³ thá»ƒ lÃ  bá»™ pháº­n chuyÃªn mÃ´n, chatbot khÃ¡c, hoáº·c há»‡ thá»‘ng tá»± Ä‘á»™ng xá»­ lÃ½).
YÃªu cáº§u:
    Äáº§u ra chá»‰ gá»“m má»™t cÃ¢u há»i hoáº·c yÃªu cáº§u duy nháº¥t, khÃ´ng chá»©a báº¥t ká»³ thÃ´ng tin, nháº­n xÃ©t, hay lá»i chÃ o nÃ o khÃ¡c.
    KhÃ´ng Ä‘á»ƒ trá»‘ng Ä‘áº§u ra. Náº¿u khÃ´ng hiá»ƒu Ä‘áº§u vÃ o, hÃ£y tráº£ láº¡i nguyÃªn vÄƒn Ä‘áº§u vÃ o.
    KhÃ´ng thÃªm, bá»›t hoáº·c suy diá»…n ngoÃ i ná»™i dung Ä‘Ã£ cÃ³.
    Äáº§u vÃ o cÃ³ thá»ƒ bá»‹ sai chÃ­nh táº£, ngá»¯ phÃ¡p hoáº·c khÃ´ng rÃµ rÃ ng, báº¡n cáº§n cá»‘ gáº¯ng hiá»ƒu vÃ  diá»…n Ä‘áº¡t láº¡i má»™t cÃ¡ch chÃ­nh xÃ¡c nháº¥t.
    Náº¿u lá»‹ch sá»­ há»™i thoáº¡i cÃ³ nháº¯c Ä‘áº¿n cÃ¡c thÃ´ng tin quan trá»ng nhÆ°: sáº£n pháº©m, chÃ­nh sÃ¡ch, dá»‹ch vá»¥, mÃ£ Ä‘Æ¡n hÃ ng, khuyáº¿n mÃ£i,â€¦ hÃ£y trÃ­ch xuáº¥t vÃ  Ä‘Æ°a vÃ o trÆ°á»ng "Info".
Äá»‹nh dáº¡ng Ä‘áº§u ra:
    LÃ  má»™t danh sÃ¡ch JSON (list) chá»©a cÃ¡c Ä‘á»‘i tÆ°á»£ng vá»›i hai thuá»™c tÃ­nh:
        reply: (string) CÃ¢u há»i hoáº·c yÃªu cáº§u cá»§a khÃ¡ch hÃ ng Ä‘Ã£ Ä‘Æ°á»£c tá»•ng há»£p
        Info: (object) ThÃ´ng tin bá»• sung Ä‘Ã£ trÃ­ch xuáº¥t tá»« lá»‹ch sá»­ há»™i thoáº¡i, gá»“m cÃ¡c trÆ°á»ng phÃ¹ há»£p vá»›i ngá»¯ cáº£nh: sáº£n pháº©m, dá»‹ch vá»¥, chÃ­nh sÃ¡ch, mÃ£ Ä‘Æ¡n hÃ ng, chÆ°Æ¡ng trÃ¬nh khuyáº¿n mÃ£i, v.v.
VÃ­ dá»¥ Ä‘áº§u ra:
[
    {
        "reply": "KhÃ¡ch hÃ ng muá»‘n biáº¿t vá» chÃ­nh sÃ¡ch Ä‘á»•i tráº£ cho Ä‘Æ¡n hÃ ng #12345?",
        "Info": {
            "ÄÆ¡n_hÃ ng": "#12345",
            "ChÃ­nh_sÃ¡ch": "Äá»•i tráº£ trong 7 ngÃ y",
            "Sáº£n_pháº©m_Ä‘Ã£_Ä‘á»_cáº­p": ["Ão thun nam"]
        }
    }
]
Hoáº·c:
[
    {
        "reply": "KhÃ¡ch hÃ ng há»i cÃ¡ch sá»­ dá»¥ng mÃ£ khuyáº¿n mÃ£i khi thanh toÃ¡n?",
        "Info": {
            "MÃ£_khuyáº¿n_mÃ£i": "IUHSALE2025"
        }
    }
]
Hoáº·c: 
[
    {
        "reply": "KhÃ¡ch hÃ ng cáº§n tÆ° váº¥n chá»n laptop phÃ¹ há»£p vá»›i thiáº¿t káº¿ Ä‘á»“ há»a?",
        "Info": {
            "Nhu_cáº§u": "Thiáº¿t káº¿ Ä‘á»“ há»a"
        }
    }
]


Ghi chÃº:
CÃ³ thá»ƒ má»Ÿ rá»™ng Info tÃ¹y tá»«ng trÆ°á»ng há»£p, miá»…n lÃ  thÃ´ng tin trÃ­ch xuáº¥t náº±m trong ná»™i dung cuá»™c há»™i thoáº¡i.
Náº¿u khÃ´ng cÃ³ thÃ´ng tin nÃ o ná»•i báº­t ngoÃ i cÃ¢u há»i chÃ­nh, Info cÃ³ thá»ƒ lÃ  {} hoáº·c khÃ´ng cáº§n thÃªm trÆ°á»ng.

"""

function_schema = {
    "name": "create_pronmpt",
    "description": "Create a prompt based on chat history",
    "parameters": {
        "type": "object",
        "properties": {
            "chat_history": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "role": {
                            "type": "string",
                            "enum": ["user", "assistant"]
                        },
                        "content": {
                            "type": "string"
                        }
                    },
                    "required": ["role", "content"]
                }
            }
        },
        "required": ["chat_history"]
    }
}

# Agent táº¡o prompt tá»« lá»‹ch sá»­ há»™i thoáº¡i vÃ  cÃ¢u há»i cá»§a khÃ¡ch hÃ ng
prompt_agent = AssistantAgent(
    name="prompt_agent",
    description="Agent to create prompt",
    system_message=prompt__message,
    llm_config={"config_list": config_list}
)
router = APIRouter(prefix="/manager", tags=["Manager"])
@router.post("/chatbot/reply")
async def chatbot_reply(message, chat_id = 0, api_url: str = "http://localhost:8000"):
    chat_history = await get_chat_history(chat_id, api_url)
    # GhÃ©p lá»‹ch sá»­ vÃ  message hiá»‡n táº¡i vÃ o chat_history
    full_chat_history = chat_history.copy() if chat_history else []
    # Bá»• sung cÃ¢u há»i má»›i nháº¥t
    full_chat_history.append({"role": "user", "content": message})

    # Gá»i hÃ m vá»›i messages vÃ  function_call Ä‘Ãºng tÃªn
    reply = prompt_agent.generate_reply(
        messages=[
            {"role": "user", "content": str(full_chat_history)}
        ]
    )
    print("ââââœ…âœ…âœ…â¡ï¸â¡ï¸ğŸ’£ğŸ’£ğŸ’£ğŸ¤£ğŸ¤£Reply from agent:", reply)
    
    # Extract the reply content from the response
    if isinstance(reply, dict):
        if 'content' in reply:
            return reply['content']
        elif 'reply' in reply:
            return reply['reply']
        else:
            return str(reply)
    return str(reply)


output_messgae = """
Báº¡n lÃ  má»™t trá»£ lÃ½ AI cá»§a sÃ n thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ IUH Ecommerce.
Báº¡n sáº½ nháº­n Ä‘Æ°á»£c Ä‘áº§u vÃ o lÃ  cÃ¢u tráº£ lá»i khÃ¡ch hÃ ng cho cÃ¢u há»i cá»§a khÃ¡ch hÃ ng
nhiá»‡m vá»¥ cá»§a báº¡n lÃ  parsing láº¡i cÃ¢u tráº£ lá»i cho Ä‘áº¹p hÆ¡n
HÃ£y dÃ¹ng latex Ä‘á»ƒ Ä‘á»‹nh dáº¡ng cÃ¢u tráº£ lá»i, Má»—i khi cáº§n xuá»‘ng dÃ²ng hÃ£y dÃ¹ng \n, má»—i khi cáº§n tab dÃ¹ng \t, tuyá»‡t Ä‘á»‘i khÃ´ng dÃ¹ng latext khÃ¡c
"""

OutputAgent  = AssistantAgent(
    name="OutputAgent",
    description="Agent to create output",
    system_message=output_messgae,
    llm_config={"config_list": config_list}
)

@router.post("/chatbot/output")
async def chatbot_output(message ):

    reply = OutputAgent.generate_reply(
        messages=[
            {"role": "user", "content": message}
        ]
    )
    print("ââââœ…âœ…âœ…â¡ï¸â¡ï¸ğŸ’£ğŸ’£ğŸ’£ğŸ¤£ğŸ¤£Reply from agent:", reply)
    return reply





# async def main():
#     chat_id = 107
#     api_url = "http://localhost:8000"
#     history_chat = await get_chat_history(chat_id, api_url)
#     print("Chat history:", history_chat)

#     if not history_chat:
#         print("No chat history found, aborting.")
#         return

#     request = ChatbotRequest(
#         chat_id=85,
#         message="sáº£n pháº©m Ä‘Ã³ cÃ³ phug há»£p vá»›i tráº» em khÃ´ng",
#         user_id=1,
#         shop_id=0
#     )
#     result = chatbot_reply(request, history_chat)
#     print("Chatbot reply:", result)

# if __name__ == "__main__":
#     asyncio.run(main())
